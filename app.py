import streamlit as st
import google.generativeai as genai
from gtts import gTTS
import speech_recognition as sr
from pydub import AudioSegment
import tempfile
import os

# --- Streamlit page config ---
st.set_page_config(page_title="Visual Chatbot", layout="centered")
st.title("ğŸ¤ Visual Chatbot")
st.markdown("Ask in **German ğŸ‡©ğŸ‡ª**, **Arabic ğŸ‡¸ğŸ‡¦**, **Urdu ğŸ‡µğŸ‡°**, or **English ğŸ‡ºğŸ‡¸** by typing or uploading an audio file!")

# --- API Key ---
API_KEY = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=API_KEY)

# --- Initialize Gemini model ---
model = genai.GenerativeModel(model_name="gemini-2.0-flash")
chat = model.start_chat()

# --- Helper Functions ---
def detect_language(text):
    urdu_chars = set("Ù¹ÚºÚ¾Ø¦Û’Û“")
    arabic_chars = set("Ø§Ø£Ø¥Ø¢Ø¡Ø¦Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙ‰ÙŠ")
    if any(c in text for c in urdu_chars):
        return "ur"
    elif any(c in text for c in arabic_chars):
        return "ar"
    elif any(c in text for c in "Ã¤Ã¶Ã¼ÃŸ"):
        return "de"
    else:
        return "en"

def speak_text(text, lang_code):
    try:
        tts = gTTS(text=text, lang=lang_code if lang_code in ["en", "de", "ar", "ur"] else "en")
        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tts.save(tmp_file.name)
        return tmp_file.name
    except Exception as e:
        st.error(f"TTS Error: {e}")
        return None

def recognize_speech(uploaded_file):
    try:
        # Save the uploaded file temporarily
        temp_input = tempfile.NamedTemporaryFile(delete=False, suffix=".input")
        temp_input.write(uploaded_file.read())
        temp_input.flush()

        # Convert audio to wav using pydub
        sound = AudioSegment.from_file(temp_input.name)
        temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        sound.export(temp_wav.name, format="wav")

        # Recognize speech
        recognizer = sr.Recognizer()
        with sr.AudioFile(temp_wav.name) as source:
            audio_data = recognizer.record(source)
            text = recognizer.recognize_google(audio_data)

        # Clean up
        os.remove(temp_input.name)
        os.remove(temp_wav.name)

        return text
    except Exception as e:
        st.error(f"Speech Recognition Failed: {e}")
        return None

# --- Input Method ---
input_method = st.radio("Choose Input Method:", ["Type âœï¸", "Upload Audio ğŸµ"])
question = ""

if input_method == "Type âœï¸":
    question = st.text_input("Type your question:")
else:
    uploaded_audio = st.file_uploader("Upload an audio file (M4A, MP3, MP4, WAV)", type=["m4a", "mp3", "mp4", "wav"])
    if uploaded_audio:
        with st.spinner("Recognizing speech..."):
            recognized_text = recognize_speech(uploaded_audio)
            if recognized_text:
                st.success(f"âœ… Recognized Text: {recognized_text}")
                question = recognized_text
            else:
                st.error("âŒ Could not recognize speech. Please try again.")

# --- Ask Gemini ---
if st.button("Ask ğŸ’¬") and question:
    with st.spinner("Thinking... ğŸ¤”"):
        prompt = f"""
You are a Visual AI Assistant.
Detect the language of the question (German, Arabic, Urdu, or English) and answer it intelligently in the same language.
Don't translate, just answer naturally.

Question:
{question}
"""
        try:
            response = chat.send_message(prompt)
            answer = response.text.strip()

            st.success("âœ… Answer:")
            st.markdown(answer)

            lang_code = detect_language(answer)
            audio_file = speak_text(answer, lang_code)

            if audio_file:
                st.audio(audio_file, format="audio/mp3")
                os.remove(audio_file)

        except Exception as e:
            st.error(f"âŒ Error: {e}")



